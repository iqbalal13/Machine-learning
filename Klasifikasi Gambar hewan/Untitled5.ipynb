{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Vocabulary size dan dimensi embedding\n",
        "vocab_size = 4  # Misal ada 4 kata dalam vocabulary\n",
        "embedding_dim = 3  # Panjang vektor embedding\n",
        "\n",
        "# Inisialisasi embedding layer\n",
        "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "# Input sequence (sebagai indeks dari kata-kata dalam vocabulary)\n",
        "input_indices = torch.tensor([0, 1, 2])  # 'saya', 'makan', 'nasi'\n",
        "\n",
        "# Mendapatkan vektor embedding untuk input\n",
        "output = embedding(input_indices)\n",
        "\n",
        "# Output\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "uZWbqdfvciXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip"
      ],
      "metadata": {
        "id": "dhjBMNh6KMcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9NycYBnK_Ks",
        "outputId": "b04a7303-5d7d-4c9b-aafc-5874a4222842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive untuk akses dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Path ke dataset training\n",
        "train_dir = '/content/drive/MyDrive/DATASET/train'\n",
        "\n",
        "# 3. Preprocessing Data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Generator untuk data training\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Ukuran input VGG16\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Generator untuk data validation\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# 4. Memuat model VGG16 tanpa layer atas (top layers)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 5. Membekukan layer-layernya agar tidak dilatih\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 6. Menambahkan layer atas (top layers) untuk klasifikasi\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(5, activation='softmax')  # Sesuaikan dengan jumlah kelas\n",
        "])\n",
        "\n",
        "# 7. Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 8. Training model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n",
        "\n",
        "# 9. Menyimpan model yang telah dilatih\n",
        "model.save('/content/drive/MyDrive/DATASET/hasil/train/vgg16_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QUqRraYLxN7",
        "outputId": "159bc77f-d9fa-40e3-9021-41ff2705faaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 400 images belonging to 5 classes.\n",
            "Found 100 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 21s 1s/step - loss: 5.1426 - accuracy: 0.2473 - val_loss: 1.1476 - val_accuracy: 0.5417\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 10s 788ms/step - loss: 2.2648 - accuracy: 0.4837 - val_loss: 0.9106 - val_accuracy: 0.5938\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 10s 817ms/step - loss: 0.8323 - accuracy: 0.6739 - val_loss: 0.8280 - val_accuracy: 0.6562\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 8s 671ms/step - loss: 0.7632 - accuracy: 0.6902 - val_loss: 0.7460 - val_accuracy: 0.7396\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 10s 812ms/step - loss: 0.7388 - accuracy: 0.6984 - val_loss: 0.6695 - val_accuracy: 0.7292\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 10s 823ms/step - loss: 0.7395 - accuracy: 0.6902 - val_loss: 0.6116 - val_accuracy: 0.7812\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 8s 674ms/step - loss: 0.6392 - accuracy: 0.7500 - val_loss: 0.7176 - val_accuracy: 0.6979\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 10s 813ms/step - loss: 0.6473 - accuracy: 0.7554 - val_loss: 0.6895 - val_accuracy: 0.7292\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 11s 964ms/step - loss: 0.6255 - accuracy: 0.7527 - val_loss: 0.5264 - val_accuracy: 0.7917\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 8s 681ms/step - loss: 0.5836 - accuracy: 0.7880 - val_loss: 0.6200 - val_accuracy: 0.7604\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 8s 676ms/step - loss: 0.5748 - accuracy: 0.7908 - val_loss: 0.6048 - val_accuracy: 0.7708\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 10s 791ms/step - loss: 0.6156 - accuracy: 0.7690 - val_loss: 0.5308 - val_accuracy: 0.8125\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 10s 822ms/step - loss: 0.6232 - accuracy: 0.7663 - val_loss: 0.6396 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 8s 677ms/step - loss: 0.4947 - accuracy: 0.8234 - val_loss: 0.5655 - val_accuracy: 0.7708\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 9s 799ms/step - loss: 0.5082 - accuracy: 0.7935 - val_loss: 0.6172 - val_accuracy: 0.7917\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 11s 987ms/step - loss: 0.5034 - accuracy: 0.8179 - val_loss: 0.4675 - val_accuracy: 0.8333\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 9s 786ms/step - loss: 0.4264 - accuracy: 0.8370 - val_loss: 0.4762 - val_accuracy: 0.8438\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 10s 818ms/step - loss: 0.4459 - accuracy: 0.8098 - val_loss: 0.4974 - val_accuracy: 0.8021\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 8s 666ms/step - loss: 0.4031 - accuracy: 0.8478 - val_loss: 0.5380 - val_accuracy: 0.7708\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 9s 790ms/step - loss: 0.4349 - accuracy: 0.8179 - val_loss: 0.6289 - val_accuracy: 0.8021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive untuk akses dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Path ke dataset testing\n",
        "test_dir = '/content/drive/MyDrive/DATASET/test'  # Ganti dengan path dataset pengujian Anda\n",
        "\n",
        "# 3. Preprocessing Data untuk testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Hanya rescaling untuk data pengujian\n",
        "\n",
        "# Generator untuk data testing\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),  # Ukuran input VGG16\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Jangan shuffle data untuk pengujian\n",
        ")\n",
        "\n",
        "# 4. Memuat model yang telah dilatih\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/DATASET/hasil/train/vgg16_model.h5')\n",
        "\n",
        "# 5. Evaluasi model menggunakan data testing\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# 6. Melakukan prediksi pada data testing\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = tf.argmax(predictions, axis=1)  # Ambil kelas dengan probabilitas tertinggi\n",
        "\n",
        "# 7. Menampilkan hasil prediksi\n",
        "true_classes = test_generator.classes  # Kelas yang sebenarnya\n",
        "class_labels = list(test_generator.class_indices.keys())  # Nama kelas\n",
        "\n",
        "# Menampilkan beberapa hasil prediksi\n",
        "for i in range(10):  # Tampilkan 10 prediksi pertama sebagai contoh\n",
        "    print(f'Predicted class: {class_labels[predicted_classes[i]]}, True class: {class_labels[true_classes[i]]}')\n",
        "\n",
        "# 8. Jika perlu, kamu bisa menghitung matriks kebingungan\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Matriks kebingungan\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tJ6flz3qV8Uc",
        "outputId": "e8e32468-5bb1-4271-a696-21192045d5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 215 images belonging to 5 classes.\n",
            "6/6 [==============================] - 2s 201ms/step - loss: 0.4246 - accuracy: 0.8177\n",
            "Test Loss: 0.4246181547641754, Test Accuracy: 0.8177083134651184\n",
            "7/7 [==============================] - 7s 1s/step\n",
            "Predicted class: anjing, True class: anjing\n",
            "Predicted class: anjing, True class: anjing\n",
            "Predicted class: domba, True class: anjing\n",
            "Predicted class: anjing, True class: anjing\n",
            "Predicted class: anjing, True class: anjing\n",
            "Predicted class: anjing, True class: anjing\n",
            "Predicted class: domba, True class: anjing\n",
            "Predicted class: domba, True class: anjing\n",
            "Predicted class: domba, True class: anjing\n",
            "Predicted class: anjing, True class: anjing\n",
            "Confusion Matrix:\n",
            "[[23 10  4  5  1]\n",
            " [ 2 33  5  2  1]\n",
            " [ 0  1 42  0  0]\n",
            " [ 0  1  2 39  1]\n",
            " [ 0  0  0  0 43]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      anjing       0.92      0.53      0.68        43\n",
            "       domba       0.73      0.77      0.75        43\n",
            "       gajah       0.79      0.98      0.88        43\n",
            "        kuda       0.85      0.91      0.88        43\n",
            "       kupu2       0.93      1.00      0.97        43\n",
            "\n",
            "    accuracy                           0.84       215\n",
            "   macro avg       0.85      0.84      0.83       215\n",
            "weighted avg       0.85      0.84      0.83       215\n",
            "\n"
          ]
        }
      ]
    }
  ]
}